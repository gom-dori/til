# TIL(Today I Learned)

## 2017-08-04

## FastC CS 08

### CALL BY REFERENCE

```python
## call by reference

a = 1024
b = 1024

print(a == b)
print(a is b) ## bcz hex(id(a)) != hex(id(b)), 메모리 주소 공간이 다르다
```

```python
## call by assignment

def func(x, v):
    print('x is a : ', x is a)
    x = v
    print('x is a :', x is a)
    
a = 10
func(a, 20)

# #result
# x is a :  True
# x is a : False
```



---



### INTEGER AND FLOAT

수 (number) == 정수(integer)와 실수 _ 양수와 음수

문자(character)와 문자형(strings)_ ASCII 와 UNICODE

- 음수의 표현 (2의 보수법 two's complement)

- 실수표현에서의 부동 소수점floating point

  ​

- 정수 (python에는 C에서 의미하는 long이 숨어있다)

  1byte / 4byte / 8 byte / 2 byte

  32bit x86에서 **character = 1byte** / **int = 4byte** 

- "9를 메모리에 저장하고싶다. 1바이트짜리 캐릭터"

  ㅁㅁㅁㅁㅁㅁㅁㅁ / 

  ㅁ 1 = 부호, 0 = 양수, 1 = 음수. so 9(chr) = 10001001

  ㅁ1 = unsigned의 경우 그냥 수로 쓴다.

- 컴퓨터 메모리에 저장하는 방식

  4321을 4321로 저장 = big endien / 1234로 저장 little endien

  ex. 0x01020304 = 01 / 02 / 03 / 04  = 4 바이트   

  ```python
  a = 0x01020304
  print(a)
  print(a.to_bytes(4, byteorder = "little", signed = True))
  #요즘 상용 아키텍쳐는 모두 little로 저장
  print(a.to_bytes(4, byteorder = "big", signed = True))

  #= 16909060
  #= b'\x04\x03\x02\x01'
  #= b'\x01\x02\x03\x04'
  ```

  ​

  ---

  ​

  ### 2의 보수법

  * +31 = 0001 111
  * -31 = 1110 0001 왜? +0, -0을 없애기 위해서, 더 많은 수를 표현하기 위해서
  * 보수 = 자릿수가 바뀌지 않은 상태에서 radix를 만들어주는 complement
  * binary에서 모든 비트를 반전시키면 1의 보수 = 자릿수를 바꾸지 않고 모두 1111
  * 거기에 1을 더하면 자리가 바뀌면서 10000... 이 된다. 

- ```
  0의 비트를 반전시키면 -1
  ```

  ​

  ---

  ​

  ### floating point 

- * 표현 범위가 넓다
  * 정밀도가 떨어진다
  * if 문에서 == 비교하면 안된다

- 부동소수점 표현을 위해

  4321 = 4.321 * 10^3

  * 4.321 = 가수부mentissa / 10 = 기수radix / 3 = 기수exponent
  * 정규화normalize >> 맨 앞 자리를 radix보다 작은 정수로 표현.  

- IEEE 754 표준

  * ±1.m*2^e-b

- float (32bit = 4byte)

- * sign : 1 bit

  * exponent : 8 bit

  * * bias : 2^n-1 / n = exponent / (2^8 -1) -1 / = 127

  * mentissa : 23 bit

    2진수 23자리이지만 사실 표현할 수 있는 수는 2진수 24자리

    왜냐하면 매번 들어가는 m앞의 1 뒷 자리이기 때문에.

- double (64bit = byte)

  - sign : 1 bit
  - exponent : 11 bit
    - bias : 2^(11-1)-1 = 1023
  - mantissa : 52 bit

- float

  17.25(10) >> 10001.01(2) #2진수로 변환

  +1.000101(2) * 2^4 #normalize

  sign = 0 / exponent =  1000 0011 / mentisa = 0001010000000

  0100 0001 1001 1010 0000 0000

  0x418A0000 >> 메모리에는 00 00 8A 41로 들어가있음 (little endien)

- floating point와 정밀도

  2진수 24자리로 10진수 몇 자리를 정밀하게(빠짐없이) 표현할 수 있나?

  - mantissa digits : 24 bit
  - 0b1111 1111 1111 1111 1111 1111 == 16,777,215 > 9,999,999
    - 정밀도 : 7자리 십진수

- double의 정밀도

  - mantissa digits : 53 bit
  - 0b1 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 == 9,007,199,254,740,991 > 999,999,999,999,999
    - 정밀도 : 15자리 십진수

- 표현할 수 있는 두 부동소수점의 차이 between two representable floats 

  - 2^(e-23)
  - 23 : mantissa bit

- ```python
  import sys
  sys.float_info
  sys.float_info(
  #maximum representable finite float
  max=1.7976931348623157e+308, 
  max_exp=1024, 
  max_10_exp=308, 
  #minimum positive normalizer float
  min=2.2250738585072014e-308, 
  min_exp=-1021, 
  min_10_exp=-307, 
  #digits : 15자리 십진수
  dig=15, 
  # mantissa digits(52 + 1)
  mant_dig=53, 
  epsilon=2.220446049250313e-16, #1과 1다음에 표현할 수 있는 수의 차이
  #radix or base : the number of unique digits
  radix=2,
  rounds=1
  ```




---



###ASCII & UNICODE

  컴퓨터는 0101밖에 모르는데 어떻게 문자를 컴퓨터에 저장할까?

  문자를 어떤 숫자로 대응시켜서(mapping) 숫자로 표현하자. 

- ASCII

  영어에서는 0-127까지만 필요함 character 자료형. 

  eg. 0이라는 숫자 문자형은 48(decimal)

- Unicode

  2byte로 늘리고 더 많은 문자와 부호를 넣는 매핑 테이블을 만듦

  모자를지도 모른다는 생각에 평면을 16개 더 만듦 UTF-16

- 유니코드의 부호화 방식 (encoding)

  * UTF - 8
  * * 8bit 기반
    * 가변 길이 유니코드 인코딩 시스템 (ex. 영어 = 1byte, 한글 = 3 byte)
  * UTF - 16
  * * BMP(Basic multilingual plane) : 다국어 기본 평면 : 16 bit
    * SMP(Supplementary Multilingual plane) 이상 : 다국어 보충 평면~ : 32 bit
  * UTF - 32
  * * 모든것을 다 32 bit 기반으로 저장.

- Windows의 부호화 방식 CP949

  * 통합형 한글코드 (unified Hangul Code)

